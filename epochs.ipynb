{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ASLoverfitting.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JasmineGhumman/SignLanguageDetection/blob/master/epochs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xajr70eVz7M4",
        "colab_type": "code",
        "outputId": "02289c15-5e3f-43b5-b18d-38b56ec8d984",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▎                               | 10kB 28.5MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 3.2MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 4.6MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 3.7MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 4.4MB/s eta 0:00:01\r\u001b[K     |██▎                             | 71kB 5.1MB/s eta 0:00:01\r\u001b[K     |██▋                             | 81kB 5.8MB/s eta 0:00:01\r\u001b[K     |███                             | 92kB 6.4MB/s eta 0:00:01\r\u001b[K     |███▎                            | 102kB 4.9MB/s eta 0:00:01\r\u001b[K     |███▋                            | 112kB 4.9MB/s eta 0:00:01\r\u001b[K     |████                            | 122kB 4.9MB/s eta 0:00:01\r\u001b[K     |████▎                           | 133kB 4.9MB/s eta 0:00:01\r\u001b[K     |████▋                           | 143kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████                           | 153kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 163kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 174kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████                          | 184kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 194kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 204kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████                         | 215kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 225kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 235kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 245kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 256kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 266kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████                       | 276kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 286kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 296kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████                      | 307kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 317kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 327kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 337kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 348kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 358kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████                    | 368kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 378kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 389kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 399kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 409kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 419kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 430kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 440kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 450kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 460kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 471kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 481kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████                | 491kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 501kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 512kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 522kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 532kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 542kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 552kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 563kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 573kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 583kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 593kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 604kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 614kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 624kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 634kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 645kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 655kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 665kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 675kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 686kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 696kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 706kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 716kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 727kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 737kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 747kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 757kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 768kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 778kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 788kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 798kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 808kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 819kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 829kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 839kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 849kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 860kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 870kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 880kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 890kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 901kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 911kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 921kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 931kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 942kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 952kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 962kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 972kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 983kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 993kB 4.9MB/s \n",
            "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKoCYjq60jTx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download a file based on its file ID.\n",
        "#\n",
        "# A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz\n",
        "'''\n",
        "file_id = '1sNVHpcnPHZiDaSQ6DhhxY1ZbdEByi5gk'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "print('Downloaded content \"{}\"'.format(downloaded.GetContentString()))\n",
        "'''\n",
        "\n",
        "fid = drive.ListFile({'q':\"title='mydata.zip'\"}).GetList()[0]['id']\n",
        "f = drive.CreateFile({'id': fid})\n",
        "f.GetContentFile('mydata.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWRBb2ht0jkq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip mydata"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-hCzsmW0jv8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "import os\n",
        "\n",
        "\n",
        "# Any results you write to the current directory are saved as output.import numpy as np # linear algebra\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PM0kNvpG0j29",
        "colab_type": "code",
        "outputId": "eb33dbcc-dff1-45b9-a366-c0af75992273",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#!pip uninstall keras\n",
        "#!pip install keras==2.0.9\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras import optimizers\n",
        "from keras.models import Model\n",
        "from keras.layers import (Activation, Dropout, Flatten, Dense, GlobalMaxPooling2D,GlobalAveragePooling2D,\n",
        "                          BatchNormalization, Input, Conv2D, Concatenate)\n",
        "'''from keras.applications import InceptionResNetV2\n",
        "conv_base= InceptionResNetV2(weights='imagenet',include_top=False,input_shape=(75,75,3))'''\n",
        "\n",
        "import keras\n",
        "import numpy as np\n",
        "from keras.applications.resnet50 import ResNet50"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFW5MMIX0j8A",
        "colab_type": "code",
        "outputId": "05668713-cec2-4e68-8288-7befce7f2f84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "res_weights_path = \"resnet50_weights.hd\"\n",
        "print(\"[INFO] loading ..\" )\n",
        "#model = ResNet50(include_top=False,input_shape=(64, 64, 3))\n",
        "base_model =ResNet50(weights='imagenet', include_top=False)\n",
        "#my_model_2 = ResNet50(weights='imagenet')\n",
        "#base_model.load_weights('../input/ResNet-50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
        "# include_top= False means that we won’t be keeping the Fully-Connected (FC) layers at the end of the model\n",
        "\n",
        "\n",
        "x0 = base_model.output\n",
        "x1 = GlobalAveragePooling2D()(x0)\n",
        "x2 = GlobalMaxPooling2D()(x0)\n",
        "x = Concatenate()([x1,x2])\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.7)(x)\n",
        "x = Dense(2048, activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.7)(x)\n",
        "predictions = Dense(26, activation='sigmoid')(x)\n",
        "model = Model(inputs=base_model.input, outputs=predictions)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading ..\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94658560/94653016 [==============================] - 2s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoJoCtvo0j1J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "for i in range(-6,0):\n",
        "    model.layers[i].trainable = True\n",
        "\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer=optimizers.SGD(lr = 0.01),metrics=['accuracy'])\n",
        "\n",
        "#model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBKIX6vA0jzF",
        "colab_type": "code",
        "outputId": "06948747-55d1-47c4-900d-582940681a5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "#Part 2 Fittting the CNN to the image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory(\n",
        "        'mydata/train',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "test_set = test_datagen.flow_from_directory(\n",
        "        'mydata/test',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 68250 images belonging to 26 classes.\n",
            "Found 9775 images belonging to 26 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_rb0NmZ0jtt",
        "colab_type": "code",
        "outputId": "4049b3f3-4025-4b32-984e-249a567e51df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2103
        }
      },
      "source": [
        "moDel = model.fit_generator(\n",
        "        training_set,\n",
        "        steps_per_epoch=60,\n",
        "        epochs=60,\n",
        "        validation_data = test_set,\n",
        "        validation_steps = 200\n",
        "      )\n",
        "\n",
        "#Saving the model\n",
        "import h5py\n",
        "model.save('Trained_model.h5')\n",
        "modelcheckpoint = keras.callbacks.ModelCheckpoint(\"keras.model\",verbose=1)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/60\n",
            "60/60 [==============================] - 56s 940ms/step - loss: 1.2383 - acc: 0.5006 - val_loss: 0.7626 - val_acc: 0.5003\n",
            "Epoch 2/60\n",
            "60/60 [==============================] - 49s 814ms/step - loss: 1.2048 - acc: 0.5083 - val_loss: 0.7288 - val_acc: 0.5033\n",
            "Epoch 3/60\n",
            "60/60 [==============================] - 47s 785ms/step - loss: 1.1762 - acc: 0.5150 - val_loss: 0.7193 - val_acc: 0.5125\n",
            "Epoch 4/60\n",
            "60/60 [==============================] - 48s 802ms/step - loss: 1.1435 - acc: 0.5249 - val_loss: 0.6955 - val_acc: 0.5725\n",
            "Epoch 5/60\n",
            "60/60 [==============================] - 47s 780ms/step - loss: 1.1216 - acc: 0.5273 - val_loss: 0.6852 - val_acc: 0.5725\n",
            "Epoch 6/60\n",
            "60/60 [==============================] - 48s 808ms/step - loss: 1.0982 - acc: 0.5309 - val_loss: 0.6681 - val_acc: 0.5741\n",
            "Epoch 7/60\n",
            "60/60 [==============================] - 48s 794ms/step - loss: 1.0726 - acc: 0.5407 - val_loss: 0.6620 - val_acc: 0.5771\n",
            "Epoch 8/60\n",
            "60/60 [==============================] - 47s 786ms/step - loss: 1.0486 - acc: 0.5467 - val_loss: 0.6369 - val_acc: 0.6147\n",
            "Epoch 9/60\n",
            "60/60 [==============================] - 49s 822ms/step - loss: 1.0249 - acc: 0.5547 - val_loss: 0.6176 - val_acc: 0.6439\n",
            "Epoch 10/60\n",
            "60/60 [==============================] - 47s 783ms/step - loss: 1.0124 - acc: 0.5555 - val_loss: 0.6097 - val_acc: 0.6507\n",
            "Epoch 11/60\n",
            "60/60 [==============================] - 48s 808ms/step - loss: 0.9910 - acc: 0.5621 - val_loss: 0.5948 - val_acc: 0.7097\n",
            "Epoch 12/60\n",
            "60/60 [==============================] - 47s 778ms/step - loss: 0.9729 - acc: 0.5682 - val_loss: 0.5852 - val_acc: 0.7119\n",
            "Epoch 13/60\n",
            "60/60 [==============================] - 48s 796ms/step - loss: 0.9436 - acc: 0.5746 - val_loss: 0.5644 - val_acc: 0.7143\n",
            "Epoch 14/60\n",
            "60/60 [==============================] - 48s 795ms/step - loss: 0.9156 - acc: 0.5854 - val_loss: 0.5520 - val_acc: 0.7132\n",
            "Epoch 15/60\n",
            "60/60 [==============================] - 48s 798ms/step - loss: 0.8983 - acc: 0.5915 - val_loss: 0.5369 - val_acc: 0.7138\n",
            "Epoch 16/60\n",
            "60/60 [==============================] - 48s 807ms/step - loss: 0.8741 - acc: 0.5998 - val_loss: 0.5270 - val_acc: 0.7192\n",
            "Epoch 17/60\n",
            "60/60 [==============================] - 47s 780ms/step - loss: 0.8509 - acc: 0.6096 - val_loss: 0.5231 - val_acc: 0.7375\n",
            "Epoch 18/60\n",
            "60/60 [==============================] - 47s 789ms/step - loss: 0.8269 - acc: 0.6172 - val_loss: 0.4992 - val_acc: 0.7622\n",
            "Epoch 19/60\n",
            "60/60 [==============================] - 48s 793ms/step - loss: 0.8097 - acc: 0.6248 - val_loss: 0.4766 - val_acc: 0.8194\n",
            "Epoch 20/60\n",
            "60/60 [==============================] - 47s 779ms/step - loss: 0.7868 - acc: 0.6335 - val_loss: 0.4642 - val_acc: 0.8253\n",
            "Epoch 21/60\n",
            "60/60 [==============================] - 48s 805ms/step - loss: 0.7607 - acc: 0.6442 - val_loss: 0.4488 - val_acc: 0.8355\n",
            "Epoch 22/60\n",
            "60/60 [==============================] - 48s 805ms/step - loss: 0.7474 - acc: 0.6502 - val_loss: 0.4203 - val_acc: 0.8895\n",
            "Epoch 23/60\n",
            "60/60 [==============================] - 48s 796ms/step - loss: 0.7330 - acc: 0.6560 - val_loss: 0.4167 - val_acc: 0.8904\n",
            "Epoch 24/60\n",
            "60/60 [==============================] - 47s 787ms/step - loss: 0.7060 - acc: 0.6683 - val_loss: 0.4091 - val_acc: 0.8906\n",
            "Epoch 25/60\n",
            "60/60 [==============================] - 47s 781ms/step - loss: 0.6698 - acc: 0.6816 - val_loss: 0.3990 - val_acc: 0.8905\n",
            "Epoch 26/60\n",
            "60/60 [==============================] - 49s 814ms/step - loss: 0.6517 - acc: 0.6909 - val_loss: 0.3864 - val_acc: 0.8906\n",
            "Epoch 27/60\n",
            "60/60 [==============================] - 47s 780ms/step - loss: 0.6325 - acc: 0.7015 - val_loss: 0.3684 - val_acc: 0.8908\n",
            "Epoch 28/60\n",
            "60/60 [==============================] - 49s 820ms/step - loss: 0.6115 - acc: 0.7093 - val_loss: 0.3594 - val_acc: 0.8925\n",
            "Epoch 29/60\n",
            "60/60 [==============================] - 47s 782ms/step - loss: 0.5830 - acc: 0.7247 - val_loss: 0.3495 - val_acc: 0.9241\n",
            "Epoch 30/60\n",
            "60/60 [==============================] - 47s 776ms/step - loss: 0.5691 - acc: 0.7325 - val_loss: 0.3361 - val_acc: 0.9444\n",
            "Epoch 31/60\n",
            "60/60 [==============================] - 48s 800ms/step - loss: 0.5414 - acc: 0.7446 - val_loss: 0.3246 - val_acc: 0.9615\n",
            "Epoch 32/60\n",
            "60/60 [==============================] - 48s 793ms/step - loss: 0.5274 - acc: 0.7518 - val_loss: 0.3105 - val_acc: 0.9615\n",
            "Epoch 33/60\n",
            "60/60 [==============================] - 49s 810ms/step - loss: 0.5107 - acc: 0.7586 - val_loss: 0.2967 - val_acc: 0.9615\n",
            "Epoch 34/60\n",
            "60/60 [==============================] - 47s 780ms/step - loss: 0.4984 - acc: 0.7676 - val_loss: 0.2906 - val_acc: 0.9615\n",
            "Epoch 35/60\n",
            "60/60 [==============================] - 49s 812ms/step - loss: 0.4666 - acc: 0.7857 - val_loss: 0.2849 - val_acc: 0.9615\n",
            "Epoch 36/60\n",
            "60/60 [==============================] - 48s 807ms/step - loss: 0.4556 - acc: 0.7916 - val_loss: 0.2705 - val_acc: 0.9615\n",
            "Epoch 37/60\n",
            "60/60 [==============================] - 47s 779ms/step - loss: 0.4416 - acc: 0.8003 - val_loss: 0.2707 - val_acc: 0.9615\n",
            "Epoch 38/60\n",
            "60/60 [==============================] - 48s 807ms/step - loss: 0.4169 - acc: 0.8113 - val_loss: 0.2716 - val_acc: 0.9615\n",
            "Epoch 39/60\n",
            "60/60 [==============================] - 48s 794ms/step - loss: 0.4194 - acc: 0.8106 - val_loss: 0.2629 - val_acc: 0.9615\n",
            "Epoch 40/60\n",
            "60/60 [==============================] - 47s 782ms/step - loss: 0.3937 - acc: 0.8264 - val_loss: 0.2483 - val_acc: 0.9615\n",
            "Epoch 41/60\n",
            "60/60 [==============================] - 48s 798ms/step - loss: 0.3737 - acc: 0.8354 - val_loss: 0.2418 - val_acc: 0.9615\n",
            "Epoch 42/60\n",
            "60/60 [==============================] - 47s 782ms/step - loss: 0.3663 - acc: 0.8398 - val_loss: 0.2304 - val_acc: 0.9615\n",
            "Epoch 43/60\n",
            "60/60 [==============================] - 48s 804ms/step - loss: 0.3577 - acc: 0.8462 - val_loss: 0.2169 - val_acc: 0.9615\n",
            "Epoch 44/60\n",
            "60/60 [==============================] - 47s 781ms/step - loss: 0.3446 - acc: 0.8511 - val_loss: 0.2114 - val_acc: 0.9615\n",
            "Epoch 45/60\n",
            "60/60 [==============================] - 48s 797ms/step - loss: 0.3398 - acc: 0.8554 - val_loss: 0.2094 - val_acc: 0.9615\n",
            "Epoch 46/60\n",
            "60/60 [==============================] - 48s 793ms/step - loss: 0.3238 - acc: 0.8631 - val_loss: 0.2072 - val_acc: 0.9615\n",
            "Epoch 47/60\n",
            "60/60 [==============================] - 47s 776ms/step - loss: 0.3068 - acc: 0.8754 - val_loss: 0.2093 - val_acc: 0.9615\n",
            "Epoch 48/60\n",
            "60/60 [==============================] - 50s 837ms/step - loss: 0.3038 - acc: 0.8757 - val_loss: 0.2027 - val_acc: 0.9615\n",
            "Epoch 49/60\n",
            "60/60 [==============================] - 47s 779ms/step - loss: 0.2947 - acc: 0.8818 - val_loss: 0.1994 - val_acc: 0.9615\n",
            "Epoch 50/60\n",
            "60/60 [==============================] - 48s 793ms/step - loss: 0.2833 - acc: 0.8872 - val_loss: 0.1925 - val_acc: 0.9615\n",
            "Epoch 51/60\n",
            "60/60 [==============================] - 47s 786ms/step - loss: 0.2782 - acc: 0.8914 - val_loss: 0.1902 - val_acc: 0.9615\n",
            "Epoch 52/60\n",
            "60/60 [==============================] - 47s 777ms/step - loss: 0.2688 - acc: 0.8961 - val_loss: 0.1875 - val_acc: 0.9615\n",
            "Epoch 53/60\n",
            "60/60 [==============================] - 47s 790ms/step - loss: 0.2655 - acc: 0.8971 - val_loss: 0.1870 - val_acc: 0.9615\n",
            "Epoch 54/60\n",
            "60/60 [==============================] - 47s 788ms/step - loss: 0.2634 - acc: 0.9011 - val_loss: 0.1866 - val_acc: 0.9615\n",
            "Epoch 55/60\n",
            "60/60 [==============================] - 48s 799ms/step - loss: 0.2480 - acc: 0.9062 - val_loss: 0.1848 - val_acc: 0.9615\n",
            "Epoch 56/60\n",
            "60/60 [==============================] - 47s 781ms/step - loss: 0.2450 - acc: 0.9090 - val_loss: 0.1835 - val_acc: 0.9615\n",
            "Epoch 57/60\n",
            "60/60 [==============================] - 47s 776ms/step - loss: 0.2446 - acc: 0.9093 - val_loss: 0.1803 - val_acc: 0.9615\n",
            "Epoch 58/60\n",
            "60/60 [==============================] - 49s 813ms/step - loss: 0.2351 - acc: 0.9149 - val_loss: 0.1783 - val_acc: 0.9615\n",
            "Epoch 59/60\n",
            "60/60 [==============================] - 46s 773ms/step - loss: 0.2331 - acc: 0.9155 - val_loss: 0.1787 - val_acc: 0.9615\n",
            "Epoch 60/60\n",
            "60/60 [==============================] - 48s 794ms/step - loss: 0.2284 - acc: 0.9170 - val_loss: 0.1752 - val_acc: 0.9615\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJ139fnP0jqP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#download model from lhs files.Save on computer. t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcrBhxCZ0joG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}